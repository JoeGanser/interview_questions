{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b6ba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.16990</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.03225</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.19620</td>\n",
       "      <td>0.174850</td>\n",
       "      <td>0.254314</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>9.58</td>\n",
       "      <td>299.630000</td>\n",
       "      <td>299.764286</td>\n",
       "      <td>295.851429</td>\n",
       "      <td>...</td>\n",
       "      <td>79.891429</td>\n",
       "      <td>9.58</td>\n",
       "      <td>17.212857</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>28.114286</td>\n",
       "      <td>6.942857</td>\n",
       "      <td>34.4</td>\n",
       "      <td>23.9</td>\n",
       "      <td>39.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.11290</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.205071</td>\n",
       "      <td>0.210271</td>\n",
       "      <td>3.48</td>\n",
       "      <td>299.207143</td>\n",
       "      <td>299.221429</td>\n",
       "      <td>295.865714</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.48</td>\n",
       "      <td>17.234286</td>\n",
       "      <td>2.042857</td>\n",
       "      <td>27.414286</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>32.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  weekofyear  ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0     1          18  0.12260  0.103725  0.198483  0.177617   \n",
       "1     1          19  0.16990  0.142175  0.162357  0.155486   \n",
       "2     1          20  0.03225  0.172967  0.157200  0.170843   \n",
       "5     1          23  0.19620  0.174850  0.254314  0.181743   \n",
       "6     1          24  0.11290  0.092800  0.205071  0.210271   \n",
       "\n",
       "   precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "0                 12.42             297.572857             297.742857   \n",
       "1                 22.82             298.211429             298.442857   \n",
       "2                 34.54             298.781429             298.878571   \n",
       "5                  9.58             299.630000             299.764286   \n",
       "6                  3.48             299.207143             299.221429   \n",
       "\n",
       "   reanalysis_dew_point_temp_k  ...  reanalysis_relative_humidity_percent  \\\n",
       "0                   292.414286  ...                             73.365714   \n",
       "1                   293.951429  ...                             77.368571   \n",
       "2                   295.434286  ...                             82.052857   \n",
       "5                   295.851429  ...                             79.891429   \n",
       "6                   295.865714  ...                             82.000000   \n",
       "\n",
       "   reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
       "0                         12.42                              14.012857   \n",
       "1                         22.82                              15.372857   \n",
       "2                         34.54                              16.848571   \n",
       "5                          9.58                              17.212857   \n",
       "6                          3.48                              17.234286   \n",
       "\n",
       "   reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "0           2.628571           25.442857                 6.900000   \n",
       "1           2.371429           26.714286                 6.371429   \n",
       "2           2.300000           26.714286                 6.485714   \n",
       "5           2.100000           28.114286                 6.942857   \n",
       "6           2.042857           27.414286                 6.771429   \n",
       "\n",
       "   station_max_temp_c  station_min_temp_c  station_precip_mm  total_cases  \n",
       "0                29.4                20.0               16.0            4  \n",
       "1                31.7                22.2                8.6            5  \n",
       "2                32.2                22.8               41.4            4  \n",
       "5                34.4                23.9               39.1            2  \n",
       "6                32.2                23.3               29.7            4  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('train.csv',index_col=0)\n",
    "df_test = pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "class etl:\n",
    "    def __init__(self,data,training=True,split_cities=True):\n",
    "        \"\"\"ETL use cases: training data, making predictions and training on the context of different cities\"\"\"\n",
    "        self.data = data\n",
    "        self.training = training\n",
    "        self.split = 0.8\n",
    "        self.split_cities = split_cities\n",
    "        \n",
    "    def transform(self):\n",
    "        \"\"\"forward fill null values and drop date/year columns\"\"\"\n",
    "        iq = self.data[self.data['city']=='iq'].sort_values(by='week_start_date',ascending=True)\n",
    "        sj = self.data[self.data['city']=='sj'].sort_values(by='week_start_date',ascending=True)\n",
    "        sj.fillna(method='ffill', inplace=True)\n",
    "        iq.fillna(method='ffill', inplace=True)\n",
    "        self.data = pd.concat([sj,iq],axis=0)\n",
    "        self.data.drop(['week_start_date','year'],axis=1,inplace=True)\n",
    "        self.data = self.format_city()\n",
    "        return self.data\n",
    "    def format_city(self):\n",
    "        \"\"\"convert the city into a machine readible variable\"\"\"\n",
    "        self.data['city'] = self.data['city'].apply(lambda x: 1 if x=='sj' else 0)\n",
    "        return self.data\n",
    "    \n",
    "    def split_data(self,df):\n",
    "        \"\"\"split the data into train and test sets\"\"\"\n",
    "        mask = np.random.rand(len(df))<self.split\n",
    "        train = df[mask]\n",
    "        test = df[~mask]\n",
    "        return train,test\n",
    "    \n",
    "    def load(self):\n",
    "        data = self.transform()\n",
    "        if self.training:\n",
    "            if self.split_cities:\n",
    "                sj = data[data['city']==1].drop('city',axis=1)\n",
    "                iq = data[data['city']==0].drop('city',axis=1)\n",
    "                sj_train,sj_test = self.split_data(sj)\n",
    "                iq_train,iq_test = self.split_data(iq)\n",
    "                return sj_train,sj_test,iq_train,iq_test\n",
    "            else:\n",
    "                return self.split_data(data)\n",
    "        else:\n",
    "            if self.split_cities:\n",
    "                sj = data[data['city']==1].drop('city',axis=1)\n",
    "                iq = data[data['city']==0].drop('city',axis=1)\n",
    "                return sj,iq\n",
    "            else:\n",
    "                return data\n",
    "    \n",
    "train, test = etl(df_train,split_cities=False).load()\n",
    "features = [j for j in df_train.columns if j not in ['week_start_date','year']]\n",
    "target = 'total_cases'\n",
    "X_train = train[features].drop(target,axis=1)\n",
    "X_test = test[features].drop(target,axis=1)\n",
    "y_train = train[target]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "988cb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error,make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#scorer = make_scorer(mean_absolute_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20185296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipe_rf = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbc60249",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(criterion='poisson', max_features='log2')\n",
      "-21.816684240993045\n"
     ]
    }
   ],
   "source": [
    "criterion = [\"squared_error\", \"absolute_error\", \"poisson\"]\n",
    "max_depth = [None,5,10,20]\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "rf_parameters = {'criterion':criterion,'max_depth':max_depth,'max_features':max_features,'max_depth':max_depth}\n",
    "rf = RandomForestRegressor()\n",
    "tree = GridSearchCV(rf, rf_parameters,scoring=scorer,cv=4)\n",
    "tree.fit(X,y)\n",
    "print(tree.best_estimator_)\n",
    "print(tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28463cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingRegressor(learning_rate=0.08099999999999999, loss='poisson')\n",
      "-16.973879517402874\n"
     ]
    }
   ],
   "source": [
    "loss = [\"squared_error\", \"absolute_error\", \"poisson\", \"quantile\"]\n",
    "learning_rate = np.arange(0.001,2,0.01)\n",
    "hgbr_params = {'loss':loss,'learning_rate':learning_rate}\n",
    "hgbr = HistGradientBoostingRegressor()\n",
    "hgbr_gs = GridSearchCV(hgbr, hgbr_params,scoring=scorer,cv=4)\n",
    "hgbr_gs.fit(X,y)\n",
    "print(hgbr_gs.best_estimator_)\n",
    "print(hgbr_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learing_rate:\n",
    "    hgbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6fe5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class count_model:\n",
    "    def __init__(self,model,params=None):\n",
    "        self.model = model()\n",
    "        if params is not None:\n",
    "            self.model = model(**params)\n",
    "    def fit(self,X,y):\n",
    "        return self.model.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        Y = self.model.predict(X)\n",
    "        #return 0 if something is negative or infinity\n",
    "        Y.fillna()\n",
    "        Y = list(map(lambda x: max(x,0),Y))\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82f8a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [\"poisson\", \"least_absolute_deviation\"]\n",
    "learning_rate = np.arange(0.001,2,0.01)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "best_err = 1000\n",
    "best_params = []   \n",
    "for l in loss:\n",
    "    for rate in learning_rate: \n",
    "        #hgbr = count_model(HistGradientBoostingRegressor,params={'loss':l,'learning_rate':rate})\n",
    "        hgbr = HistGradientBoostingRegressor(loss=l,learning_rate=rate)\n",
    "        pipe_hgbr = Pipeline([('scaler', StandardScaler()), ('hgbr',hgbr)])\n",
    "        pipe_hgbr.fit(X_train,y_train)\n",
    "        y_pred = pipe_hgbr.predict(X_test)\n",
    "        y_pred[y_pred == inf] = 0\n",
    "        err = mean_absolute_error(y_test,y_pred)\n",
    "        if err<best_err:\n",
    "            best_err = err\n",
    "            if len(best_params)!=0:\n",
    "                best_params.pop()\n",
    "            best_params.append([l,rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53f809ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['poisson', 0.10099999999999998]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "073b3eb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.376952060247417"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5bcb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
